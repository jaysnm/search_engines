{
 "cells": [
  {
   "source": [
    "## Pre-requisites\n",
    "\n",
    "For this exercise, we shall use solr in single node mode.  \n",
    "There are a number of alternative ways to run solr including using a [docker image](https://hub.docker.com/_/solr) but for this exercise we shall use distributed binaries downloaded from [here](https://solr.apache.org/downloads.html).  \n",
    "I assume you are using Linux or Mac. For windows users, all other commands will work with no modification except the command used for indexing documents. \n",
    "\n",
    "- Download and extract solr distribution archive to a directory of your choosing  \n",
    "    - `curl <download-link> && tar -xzf solr-{version}.tgz`  \n",
    "- Change directory to the decompressed binary directory  \n",
    "    - `cd solr-{version}`  \n",
    "- Launch solr in single node mode, run the process in the foreground  \n",
    "    - `bin/solr start -f`  \n",
    "- On aother terminal window or new tab in current terminal, create films core   \n",
    "    - `bin/solr create -c films`. # Note that here we have not defined configset for films core! Solr creates the core with _default configuration files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "happy-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "import requests\n",
    "\n",
    "host = 'http://localhost:8983/solr'\n",
    "core = 'films'\n",
    "search_url = host + '/' + core + '/select?q='\n",
    "headers = {\n",
    "    'Content-type':'application/json'\n",
    "}\n",
    "\n",
    "def search_query(query):\n",
    "    query = requests.utils.quote(query)\n",
    "    req = requests.get(search_url + query, headers=headers)\n",
    "    if req.status_code == 200:\n",
    "        result = json.loads(req.text)\n",
    "        print(f\"Matching documents count {result['response']['numFound']}\")\n",
    "        print(json.dumps(result['response']['docs'], indent=1))\n",
    "    else:\n",
    "        print(req.status_code, req.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stuffed-remark",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n  \"responseHeader\":{\n    \"status\":0,\n    \"QTime\":389}}\n\n"
     ]
    }
   ],
   "source": [
    "# set up custom schema settings\n",
    "schema = {\n",
    "    \"add-field\": \n",
    "    [\n",
    "        {\n",
    "            \"name\":\"name\", \n",
    "            \"type\":\"text_general\", \n",
    "            \"multiValued\":False, \n",
    "            \"stored\":True\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"genre\", \n",
    "            \"type\":\"text_general\", \n",
    "            \"multiValued\":True, \n",
    "            \"stored\":True\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "r = requests.post(host+\"/\"+collection+'/schema', json=schema)\n",
    "if r.status_code == 200:\n",
    "    print(r.text)\n",
    "else:\n",
    "    print(r.status_code, r.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "defensive-session",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n  \"responseHeader\":{\n    \"status\":0,\n    \"QTime\":275}}\n\n"
     ]
    }
   ],
   "source": [
    "#  set up a \"catchall field\" by defining a copy field that will take all data from all fields\n",
    "schema = {\n",
    "    \"add-copy-field\": \n",
    "    {\n",
    "        \"source\":\"*\",\n",
    "        \"dest\":\"_text_\"\n",
    "    }\n",
    "}\n",
    "r = requests.post(host+\"/\"+collection+'/schema', json=schema)\n",
    "if r.status_code == 200:\n",
    "    print(r.text)\n",
    "else:\n",
    "    print(r.status_code, r.reason)"
   ]
  },
  {
   "source": [
    "## Index sample films data after schema definition\n",
    "- `bin/post -c films example/films/films.json*` for linux/mac users\n",
    "- `java -jar -Dc=films -Dauto example\\exampledocs\\post.jar example\\films\\*.json` for windows users"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "negative-insurance",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Matching documents count 284\n[\n {\n  \"id\": \"/en/anamorph\",\n  \"genre\": [\n   \"Psychological thriller\",\n   \"Crime Fiction\",\n   \"Thriller\",\n   \"Mystery\",\n   \"Crime Thriller\",\n   \"Suspense\"\n  ],\n  \"directed_by\": [\n   \"H.S. Miller\"\n  ],\n  \"name\": \"Anamorph\",\n  \"_version_\": 1695550362411335681\n },\n {\n  \"id\": \"/en/blood_work\",\n  \"directed_by\": [\n   \"Clint Eastwood\"\n  ],\n  \"initial_release_date\": [\n   \"2002-08-09T00:00:00Z\"\n  ],\n  \"name\": \"Blood Work\",\n  \"genre\": [\n   \"Mystery\",\n   \"Crime Thriller\",\n   \"Thriller\",\n   \"Suspense\",\n   \"Crime Fiction\",\n   \"Detective fiction\",\n   \"Drama\"\n  ],\n  \"_version_\": 1695550362494173186\n },\n {\n  \"id\": \"/en/brigham_city_2001\",\n  \"directed_by\": [\n   \"Richard Dutcher\"\n  ],\n  \"name\": \"Brigham City\",\n  \"genre\": [\n   \"Mystery\",\n   \"Indie film\",\n   \"Crime Fiction\",\n   \"Thriller\",\n   \"Crime Thriller\",\n   \"Drama\"\n  ],\n  \"_version_\": 1695550362510950401\n },\n {\n  \"id\": \"/en/brother\",\n  \"directed_by\": [\n   \"Takeshi Kitano\"\n  ],\n  \"name\": \"Brother\",\n  \"genre\": [\n   \"Thriller\",\n   \"Crime Fiction\"\n  ],\n  \"_version_\": 1695550362516193280\n },\n {\n  \"id\": \"/en/freedomland\",\n  \"initial_release_date\": [\n   \"2006-02-17T00:00:00Z\"\n  ],\n  \"name\": \"Freedomland\",\n  \"directed_by\": [\n   \"Joe Roth\"\n  ],\n  \"genre\": [\n   \"Mystery\",\n   \"Thriller\",\n   \"Crime Fiction\",\n   \"Film adaptation\",\n   \"Crime Thriller\",\n   \"Crime Drama\",\n   \"Drama\"\n  ],\n  \"_version_\": 1695550362649362435\n },\n {\n  \"id\": \"/en/brick_2006\",\n  \"directed_by\": [\n   \"Rian Johnson\"\n  ],\n  \"initial_release_date\": [\n   \"2006-04-07T00:00:00Z\"\n  ],\n  \"name\": \"Brick\",\n  \"genre\": [\n   \"Film noir\",\n   \"Indie film\",\n   \"Teen film\",\n   \"Neo-noir\",\n   \"Mystery\",\n   \"Crime Thriller\",\n   \"Crime Fiction\",\n   \"Thriller\",\n   \"Detective fiction\",\n   \"Drama\"\n  ],\n  \"_version_\": 1695550362509901824\n },\n {\n  \"id\": \"/en/american_gangster\",\n  \"initial_release_date\": [\n   \"2007-10-19T00:00:00Z\"\n  ],\n  \"genre\": [\n   \"Crime Fiction\",\n   \"War film\",\n   \"Crime Thriller\",\n   \"Historical period drama\",\n   \"Biographical film\",\n   \"Crime Drama\",\n   \"Gangster Film\",\n   \"True crime\",\n   \"Drama\"\n  ],\n  \"directed_by\": [\n   \"Ridley Scott\"\n  ],\n  \"name\": \"American Gangster\",\n  \"_version_\": 1695550362398752769\n },\n {\n  \"id\": \"/en/after_innocence\",\n  \"genre\": [\n   \"Documentary film\",\n   \"Crime Fiction\",\n   \"Political cinema\",\n   \"Culture &amp; Society\",\n   \"Law &amp; Crime\",\n   \"Biographical film\"\n  ],\n  \"directed_by\": [\n   \"Jessica Sanders\"\n  ],\n  \"name\": \"After Innocence\",\n  \"_version_\": 1695550362362052609\n },\n {\n  \"id\": \"/en/be_cool\",\n  \"directed_by\": [\n   \"F. Gary Gray\"\n  ],\n  \"initial_release_date\": [\n   \"2005-03-04T00:00:00Z\"\n  ],\n  \"name\": \"Be Cool\",\n  \"genre\": [\n   \"Crime Fiction\",\n   \"Crime Comedy\",\n   \"Comedy\"\n  ],\n  \"_version_\": 1695550362462715905\n },\n {\n  \"id\": \"/en/elvis_has_left_the_building_2004\",\n  \"directed_by\": [\n   \"Joel Zwick\"\n  ],\n  \"genre\": [\n   \"Action Film\",\n   \"Action/Adventure\",\n   \"Road movie\",\n   \"Crime Comedy\",\n   \"Crime Fiction\",\n   \"Comedy\"\n  ],\n  \"name\": \"Elvis Has Left the Building\",\n  \"_version_\": 1695550362621050881\n }\n]\n"
     ]
    }
   ],
   "source": [
    "# query movies where genre involves crime fiction scenes\n",
    "search_query(\"Crime Fiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Matching documents count 1100\n\nFacet counts\n\n{\n \"genre\": [\n  \"film\",\n  793,\n  \"drama\",\n  569,\n  \"comedy\",\n  417,\n  \"romance\",\n  270,\n  \"thriller\",\n  266,\n  \"fiction\",\n  263,\n  \"action\",\n  208,\n  \"crime\",\n  191,\n  \"cinema\",\n  184,\n  \"adventure\",\n  167,\n  \"world\",\n  167,\n  \"indie\",\n  144,\n  \"horror\",\n  122,\n  \"family\",\n  116,\n  \"musical\",\n  93,\n  \"romantic\",\n  93,\n  \"fantasy\",\n  87,\n  \"science\",\n  82,\n  \"mystery\",\n  78,\n  \"biographical\",\n  74,\n  \"documentary\",\n  73,\n  \"animation\",\n  60,\n  \"sports\",\n  58,\n  \"teen\",\n  58,\n  \"historical\",\n  53,\n  \"of\",\n  51\n ]\n}\n"
     ]
    }
   ],
   "source": [
    "# apply faceting\n",
    "def basic_facet(facet_field, facet_mincount=20):\n",
    "    url = search_url + '*:*&rows=0&facet=on&facet.field={}&facet.mincount={}&wt=json'.format(facet_field, facet_mincount)\n",
    "    req = requests.get(url, headers=headers)\n",
    "    if req.status_code == 200:\n",
    "        result = json.loads(req.text)\n",
    "        print(f\"Matching documents count {result['response']['numFound']}\")\n",
    "        print(\"\\nFacet counts\\n\")\n",
    "        print(json.dumps(result['facet_counts']['facet_fields'], indent=1))\n",
    "    else:\n",
    "        print(req.status_code, req.reason)\n",
    "\n",
    "basic_facet(facet_field='genre', facet_mincount=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Matching documents count 1100\n{\n \"initial_release_date\": {\n  \"counts\": [\n   \"2001-03-29T09:43:09.582Z\",\n   103,\n   \"2002-03-29T09:43:09.582Z\",\n   114,\n   \"2003-03-29T09:43:09.582Z\",\n   134,\n   \"2004-03-29T09:43:09.582Z\",\n   157,\n   \"2005-03-29T09:43:09.582Z\",\n   197,\n   \"2006-03-29T09:43:09.582Z\",\n   127,\n   \"2007-03-29T09:43:09.582Z\",\n   34,\n   \"2008-03-29T09:43:09.582Z\",\n   8,\n   \"2009-03-29T09:43:09.582Z\",\n   5,\n   \"2010-03-29T09:43:09.582Z\",\n   1\n  ],\n  \"gap\": \"+1YEAR\",\n  \"start\": \"2001-03-29T09:43:09.582Z\",\n  \"end\": \"2011-03-29T09:43:09.582Z\"\n }\n}\n"
     ]
    }
   ],
   "source": [
    "# range faceting, used to partition numeric and date fields into ranges\n",
    "def advanced_faceting(facet_condition, out_var):\n",
    "    url = search_url + '*:*&rows=0&facet=on&{}&wt=json'.format(facet_condition)\n",
    "    req = requests.get(url, headers=headers)\n",
    "    if req.status_code == 200:\n",
    "        result = json.loads(req.text)\n",
    "        print(f\"Matching documents count {result['response']['numFound']}\")\n",
    "        return result['facet_counts'][out_var] \n",
    "    else:\n",
    "        print(req.status_code, req.reason)\n",
    "    return None\n",
    "# Request for all films and group them by year starting with 20 years ago - earliest film release date is 2000 - and ending today less ten years (2010).\n",
    "facet_condition = 'facet.range=initial_release_date&facet.range.start=NOW-20YEAR&facet.range.end=NOW-10YEAR&facet.range.gap={}YEAR'.format(requests.utils.quote(\"+1\"))\n",
    "facets = advanced_faceting(facet_condition, 'facet_ranges')\n",
    "print(json.dumps(facets, indent=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Matching documents count 1100\n{\n \"field\": \"genre\",\n \"value\": \"adventure\",\n \"count\": 167,\n \"pivot\": [\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"david\",\n   \"count\": 10\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"john\",\n   \"count\": 9\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"tim\",\n   \"count\": 5\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"brian\",\n   \"count\": 4\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"kevin\",\n   \"count\": 4\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"paul\",\n   \"count\": 4\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"robert\",\n   \"count\": 4\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"scott\",\n   \"count\": 4\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"bob\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"boll\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"eric\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"kitamura\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"molina\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"ryuhei\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"shakespeare\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"steve\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"terry\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"tony\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"uwe\",\n   \"count\": 3\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"adam\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"anderson\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"andrzej\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"bartkowiak\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"burton\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"chris\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"christopher\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"colin\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"frank\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"gary\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"j\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"joel\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"joseph\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"lafia\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"lima\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"mamoru\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"mark\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"mcginty\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"michael\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"moore\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"nichol\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"r\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"ridley\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"s\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"sam\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"simon\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"steven\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"tom\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"van\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"yates\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"zemeckis\",\n   \"count\": 2\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"a\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"aaron\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"abe\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"agust\\u00edn\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"akane\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"alec\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"alfonso\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"ali\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"allen\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"andrew\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"anka\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"antoine\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"ashutosh\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"balcomb\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"barron\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"barry\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"bart\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"ben\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"berg\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"blair\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"blaise\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"bolger\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"bowers\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"bowman\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"bradshaw\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"brady\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"brett\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"burke\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"byron\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"c\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"cameron\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"campbell\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"canuel\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"carpenter\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"chen\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"ching\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"christian\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"christophe\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"clive\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"columbus\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"coraci\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"corey\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"corsiglia\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"cox\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"cuar\\u00f3n\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"curt\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"daniel\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"danny\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"davis\",\n   \"count\": 1\n  },\n  {\n   \"field\": \"directed_by\",\n   \"value\": \"dicillo\",\n   \"count\": 1\n  }\n ]\n}\n"
     ]
    }
   ],
   "source": [
    "# Pivot Facets, also known as \"decision trees\", allowing two or more fields to be nested for all the various possible combinations\n",
    "facet_condition = 'facet=on&facet.pivot=genre,directed_by'\n",
    "facets = advanced_faceting(facet_condition, 'facet_pivot')\n",
    "if facets is not None:\n",
    "    print(json.dumps(facets['genre,directed_by'][9], indent=1))"
   ]
  },
  {
   "source": [
    "## Updating Data  \n",
    "Solr uses `uniqueKey` field called `id` to uniquely identify indexed documents. Whenever you `POST` to `Solr` to add a document with the same value for the `uniqueKey` as an existing document, `Solr` automatically replaces it for you. In other words, to update a document with fresh details, `POST` the new document with same `id` as the existing document to be updated."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Deleting Data\n",
    "\n",
    "Execute the following command to delete a specific document:\n",
    "\n",
    "`bin/post -c films -d \"<delete><id>/en/45_2006</id></delete>\"`\n",
    "\n",
    "To delete all documents, you can use \"delete-by-query\" command like:\n",
    "\n",
    "`bin/post -c films -d \"<delete><query>*:*</query></delete>\"`\n",
    "\n",
    "You can also modify the above to only delete documents that match a specific query.\n",
    "\n",
    "`bin/post -c films -d \"<delete><query>genre:crime</query></delete>\"`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('searchengine')",
   "metadata": {
    "interpreter": {
     "hash": "5c42fe252a17680b3092c13cff773c6bfaaa54f0dea3a1659c27a632305033c6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}